{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ltr.client import ElasticClient\n",
    "client = ElasticClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download & Build Index (run once)\n",
    "\n",
    "If you don't already have the downloaded dependencies; if you don't have TheMovieDB data indexed run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_collection_name(src_movie, base_doc):\n",
    "    if 'belongs_to_collection' in src_movie and src_movie['belongs_to_collection'] is not None:\n",
    "        if 'name' in src_movie['belongs_to_collection']:\n",
    "            base_doc['collection_name'] = src_movie['belongs_to_collection']['name']\n",
    "    return base_doc\n",
    "\n",
    "from ltr.index import rebuild_tmdb\n",
    "rebuild_tmdb(client, enrich=add_collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for movie titles\n",
    "\n",
    "We'll be searching movie titles (think searching for a specific movie on Netflix). And we have a set of judgments around the appropriatte movie to return. IE search for \"Star Wars\" return good star wars matches, in quality order...\n",
    "\n",
    "These cover various aspects of the problem (searching title by phrase, title bm25 score, release date, etc). We'll use this to explore and analyze a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Default LTR feature store [Status: 200]\n",
      "Initialize Default LTR feature store [Status: 200]\n",
      "Create title_rf feature set [Status: 201]\n"
     ]
    }
   ],
   "source": [
    "config = {\"validation\": {\n",
    "              \"index\": \"tmdb\",\n",
    "              \"params\": {\n",
    "                  \"keywords\": \"rambo\"\n",
    "              }\n",
    "    \n",
    "           },\n",
    "           \"featureset\": {\n",
    "            \"features\": [\n",
    "            {\n",
    "                \"name\": \"title_phrase\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"constant_score\": {\n",
    "                        \"filter\": {\n",
    "                            \"match_phrase\": {\"title\": \"{{keywords}}\"}\n",
    "                        },\n",
    "                        \"boost\": 1.0\n",
    "                    }  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"title\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"constant_score\": {\n",
    "                        \"filter\": {\n",
    "                            \"match\": {\"title\": \"{{keywords}}\"}\n",
    "                        },\n",
    "                        \"boost\": 1.0\n",
    "                    }  \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"title_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"title\": \"{{keywords}}\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"overview_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"overview\": \"{{keywords}}\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"overview_phrase_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match_phrase\": {\"overview\": \"{{keywords}}\"}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"title_fuzzy\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"title\": \n",
    "                                {\"query\": \"{{keywords}}\",\n",
    "                                 \"fuzziness\": \"AUTO\"}}\n",
    "                }\n",
    "            },\n",
    "             {\n",
    "                \"name\": \"release_year\",\n",
    "                \"params\": [],\n",
    "                \"template\": {\n",
    "                    \"function_score\": {\n",
    "                        \"field_value_factor\": {\n",
    "                            \"field\": \"release_year\",\n",
    "                            \"missing\": 2000\n",
    "                        },\n",
    "                        \"query\": { \"match_all\": {} }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"coll_name_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match\": {\"collection_name\": \n",
    "                                {\"query\": \"{{keywords}}\"}}\n",
    "                }\n",
    "            },\n",
    "             {\n",
    "                \"name\": \"coll_name_phrase_bm25\",\n",
    "                \"params\": [\"keywords\"],\n",
    "                \"template\": {\n",
    "                    \"match_phrase\": {\"collection_name\": \n",
    "                                {\"query\": \"{{keywords}}\"}}\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            \n",
    "            ]\n",
    "    }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from ltr import setup\n",
    "setup(client, config=config, index='tmdb', featureset='title_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Generation\n",
    "\n",
    "Log out features for each of the above queries out to a training set file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 40 queries...\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for rambo (0/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for rocky (1/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for war games (2/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for crocodile dundee (3/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for matrix (4/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for contact (5/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for space jam (6/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for battlestar galactica (7/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for her (8/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for jobs (9/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for social network (10/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for rocky horror (11/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for shawshank redemption (12/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for french connection (13/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for star wars new hope (14/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for lego batman (15/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for crouching tiger hidden dragon (16/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for fight club (17/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for die hard (18/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for last temptation of christ (19/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for tree of life (20/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for murray saves christmas (21/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for black swan (22/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for emma (23/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for mad max fury road (24/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for kung fury (25/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for mr smith goes to washington (26/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for kill bill (27/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for the godfather (28/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for pulp fiction (29/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for christmas vacation (30/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for psycho (31/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for life is beautiful (32/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for dark knight (33/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for the green mile (34/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for forrest gump (35/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for top gun (36/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for how to train your dragon (37/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for how to train your dragon 2 (38/40)\n",
      "Searching tmdb - [{'terms': {'_id': [ [Status: 200]\n",
      "REBUILDING TRAINING DATA for star wars (39/40)\n",
      "Discarded 0 Keep 1390\n"
     ]
    }
   ],
   "source": [
    "from ltr.log import judgments_to_training_set\n",
    "trainingSet = judgments_to_training_set(client, \n",
    "                                        judgmentInFile='data/title_judgments.txt', \n",
    "                                        trainingOutFile='data/title_rf_judgments_train.txt', \n",
    "                                        featureSet='title_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Selections\n",
    "\n",
    "Feature searches are very time consuming for anything other than trivial data. To deal with feature dependencies, one strategy is to select a random subset of features at every decision tree split for consideration. This prevents overfitting and allows feature impacts to give a more accurate impact to how they effect the relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running java -jar data/RankyMcRankFace.jar -ranker 8 -metric2t NDCG@10 -tree 100 -bag 1 -leaf 4 -train data/title_rf_judgments_train.txt -save data/title_rf_model.txt  -feature features.txt  -kcv 5 \n",
      "DONE\n",
      "\n",
      "Impact of each feature on the model\n",
      "3 - 9.382218556036284\n",
      "6 - 1.9349179859698624\n",
      "4 - 1.2775141769150764\n",
      "1 - 0.9987069005026618\n",
      "2 - 0.23289798113217317\n",
      "7 - 0.15750725027092136\n",
      "5 - 0.005959954174888\n",
      "8 - 0.0\n",
      "9 - 0.0\n",
      "Test NDCG@10 0.8807\n"
     ]
    }
   ],
   "source": [
    "from ltr.train import kcv\n",
    "res  = kcv(client,\n",
    "            trainingInFile='data/title_rf_judgments_train.txt',\n",
    "            metric2t='NDCG@10',\n",
    "            leafs=4,\n",
    "            trees=100,\n",
    "            ranker=8, # Use a \"Random Forests Model\"\n",
    "            frate=0.5,\n",
    "            bag=1, # Number of ensembles in the forest bag=1, 1 LambdaMART model with random features chosen\n",
    "            index='tmdb',\n",
    "            kcv=5,\n",
    "            features=[1,2,3,4,5,6,7,8,9],\n",
    "            featureSet='title_rf',\n",
    "            modelName='title_rf')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in res.trainingLogs[0].impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "    \n",
    "print(\"Test NDCG@10 %s\" % res.kcvTestAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running java -jar data/RankyMcRankFace.jar -ranker 8 -metric2t NDCG@10 -tree 100 -bag 3 -leaf 4 -train data/title_rf_judgments_train.txt -save data/title_rf_model.txt  -feature features.txt \n",
      "DONE\n",
      "Delete model title_rf: 200\n",
      "Created Model title_rf [Status: 201]\n"
     ]
    }
   ],
   "source": [
    "from ltr.train import train\n",
    "res  = train(client,\n",
    "             trainingInFile='data/title_rf_judgments_train.txt',\n",
    "             metric2t='NDCG@10',\n",
    "             leafs=4,\n",
    "             trees=100,\n",
    "             ranker=8, # Use a \"Random Forests Model\"\n",
    "             frate=0.5,\n",
    "             bag=3, # Number of ensembles in the forest bag=1, 1 LambdaMART model with random features chosen\n",
    "             index='tmdb',\n",
    "             features=[1,2,3,4,5,6,7,8,9],\n",
    "             featureSet='title_rf',\n",
    "             modelName='title_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whoopsie Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched FeatureSet title_rf [Status: 200]\n",
      "Recognizing 40 queries...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Whoopsies only support LambdaMART of Random Forest of bags=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4eb0142b3d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m model = eval_model(modelName='title_rf',\n\u001b[1;32m     12\u001b[0m                        \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                        judgments=rambo)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/ltr/MART_model.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(modelName, features, judgments)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/{}_model.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mensembleXml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMARTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensembleXml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudgmentList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/ltr/MART_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ranklib_xml, features)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Whoopsies only support LambdaMART of Random Forest of bags=1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mheaderAt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Whoopsies only support LambdaMART of Random Forest of bags=1"
     ]
    }
   ],
   "source": [
    "from ltr.client import ElasticClient\n",
    "from ltr.MART_model import eval_model\n",
    "from ltr.judgments import judgments_from_file, judgments_by_qid\n",
    "\n",
    "features, _ = client.feature_set(index='tmdb', name='title_rf')\n",
    "\n",
    "judgmentDict = judgments_by_qid(judgments_from_file(filename='data/title_rf_judgments_train.txt'))\n",
    "\n",
    "\n",
    "rambo=judgmentDict[1]\n",
    "model = eval_model(modelName='title_rf',\n",
    "                       features=features,\n",
    "                       judgments=rambo)\n",
    "\n",
    "print()\n",
    "print(\"## Evaluating graded docs for search keywords '%s'\" % rambo[0].keywords)\n",
    "print()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
